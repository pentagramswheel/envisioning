{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Wil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import data cleaning libraries\n",
    "import bs4 as bs\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wil\\anaconda3\\envs\\data-x\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries for topic detection\n",
    "# if torch.cuda can't be properly installed, then switch to training with \"cpu\" instead of \"cuda\"\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-win_amd64.whl \n",
    "# !pip install torchvision\n",
    "\n",
    "# !conda create -n data-x python=3.8 anaconda\n",
    "# !conda activate data-x\n",
    "# !conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "# !pip install intel-openmp\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glass_door_review_cleaner(reviews):\n",
    "    \"\"\"\n",
    "    Cleans a review retrieved from the Glass Door scraper.\n",
    "    \n",
    "    Args:\n",
    "        reviews::[pd.DataFrame]\n",
    "            The table of given reviews and their statistics.\n",
    "            \n",
    "    Return:\n",
    "       clean_reviews::[pd.DataFrame]\n",
    "            The cleaned version of the reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_reviews = reviews.drop([\"date\", \"employee_title\", \"employee_status\"], axis = 1)\n",
    "    \n",
    "    # remove newline characters\n",
    "    clean_reviews['pros'] = clean_reviews['pros'].str.replace('\\n', '', regex = True)\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace('\\n', '', regex = True)\n",
    "\n",
    "    # remove bad strings caught by the web scraper\n",
    "    badString1 = \"Verify your email to continue reading or Resend email\"\n",
    "    badString2 = \"Be the first to find this review helpfulHelpfulShareRepor\"\n",
    "\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace(badString1, '', regex = True)\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace(badString2, '', regex = True)\n",
    "\n",
    "    # compile pros and cons together into a column\n",
    "    clean_reviews[\"text\"] = \"{ Pros. \" + clean_reviews['pros'] + \" } { Cons. \" + clean_reviews['cons'] + \" }\"\n",
    "\n",
    "    # remove empty reviews\n",
    "    clean_reviews = clean_reviews.dropna(subset = ['text'])\n",
    "    clean_reviews = clean_reviews.reset_index(drop = True)\n",
    "    \n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_review_cleaner(reviews, lemmatize = True, stem = False):\n",
    "    \"\"\"\n",
    "    Clean and preprocess a review.\n",
    "\n",
    "    Args:\n",
    "        reviews::[pd.DataFrame]\n",
    "            The table of given reviews and their statistics.\n",
    "        lemmatize::[boolean]\n",
    "            A flag for feature lemmatization.\n",
    "        stem::[boolean]\n",
    "            A flag for feature stemming.\n",
    "            \n",
    "    Return:\n",
    "        cleaned_reviews::[pd.DataFrame]\n",
    "            The cleaned version of the reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    #1. Remove HTML tags\n",
    "    cleaned_reviews=[]\n",
    "    for i,review in enumerate(reviews['text']):\n",
    "    # print progress\n",
    "        if( (i+1)%500 == 0 ):\n",
    "            print(\"Done with %d reviews\" %(i+1))\n",
    "        review = bs.BeautifulSoup(review).text\n",
    "\n",
    "        #2. Use regex to find emoticons\n",
    "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
    "\n",
    "        #3. Remove punctuation\n",
    "        review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
    "\n",
    "        #4. Tokenize into words (all lower case)\n",
    "        review = review.lower().split()\n",
    "\n",
    "        #5. Remove stopwords\n",
    "        eng_stopwords = set(stopwords.words(\"english\"))\n",
    "            \n",
    "        clean_review = []\n",
    "        for word in review:\n",
    "            if word not in eng_stopwords:\n",
    "                if lemmatize is True:\n",
    "                    word = wnl.lemmatize(word)\n",
    "                elif stem is True:\n",
    "                    if word == 'oed':\n",
    "                        continue\n",
    "                    word = ps.stem(word)\n",
    "                clean_review.append(word)\n",
    "\n",
    "        #6. Join the review to one sentence\n",
    "        review_processed = ' '.join(clean_review + emoticons)\n",
    "        cleaned_reviews.append(review_processed)\n",
    "    \n",
    "    return cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def round_two_digit_string(x):\n",
    "    \"\"\"\n",
    "    Rounds a float to two decimal places.\n",
    "    \n",
    "    Args:\n",
    "        x::[float]\n",
    "            The float number to round.\n",
    "            \n",
    "    Return:\n",
    "            The rounded float.\n",
    "    \"\"\"\n",
    "    return str(round(x, 2))\n",
    "\n",
    "def retrieve_sentiment_analysis(df, column):\n",
    "    \"\"\" Performs a sentiment analysis on the given data.\n",
    "    \n",
    "    Args:\n",
    "        df::[pd.DataFrame]\n",
    "            The table of given reviews and their statistics.\n",
    "            \n",
    "    Return:\n",
    "        sentiment_df::[pd.DataFrame]\n",
    "            The reviews with their sentiment analysis data.\n",
    "    \"\"\"\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    data = {\n",
    "        \"text\": [],\n",
    "        \"negative\": [],\n",
    "        \"neutral\": [],\n",
    "        \"positive\": [],\n",
    "        \"compound\": []\n",
    "    }\n",
    "\n",
    "    for sentence in df[column]:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "\n",
    "        data[\"text\"].append(sentence)\n",
    "        data[\"negative\"].append(round_two_digit_string(vs[\"neg\"]))\n",
    "        data[\"neutral\"].append(round_two_digit_string(vs[\"neu\"]))\n",
    "        data[\"positive\"].append(round_two_digit_string(vs[\"pos\"]))\n",
    "        data[\"compound\"].append(round_two_digit_string(vs[\"compound\"]))\n",
    "        \n",
    "    sentiment_df = pd.DataFrame(data)\n",
    "    \n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Initial_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>insurance</th>\n",
       "      <th>safety</th>\n",
       "      <th>balance</th>\n",
       "      <th>retirement</th>\n",
       "      <th>culture</th>\n",
       "      <th>racism</th>\n",
       "      <th>sexism</th>\n",
       "      <th>ageism</th>\n",
       "      <th>benefits</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>privacy</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5145.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>Work life balance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5134.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>Many opportunities off program to explore diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5132.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>Flexible Leadership is strong Challenging Lear...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5126.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>Collaborative culture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5123.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>Culture Work ethics technology quality experts.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Initial_ID                                               text  \\\n",
       "0  5145.0       743.0                                  Work life balance   \n",
       "1  5134.0       732.0  Many opportunities off program to explore diff...   \n",
       "2  5132.0       730.0  Flexible Leadership is strong Challenging Lear...   \n",
       "3  5126.0       724.0                              Collaborative culture   \n",
       "4  5123.0       721.0   Culture Work ethics technology quality experts.    \n",
       "\n",
       "   insurance  safety  balance  retirement  culture  racism  sexism  ageism  \\\n",
       "0          0       0        1           0        0       0       0       0   \n",
       "1          0       0        0           0        0       0       0       0   \n",
       "2          0       0        1           0        0       0       0       0   \n",
       "3          0       0        0           0        1       0       0       0   \n",
       "4          0       0        0           0        1       0       0       0   \n",
       "\n",
       "   benefits  opportunities  privacy  resources  \n",
       "0         0              0        0          0  \n",
       "1         0              1        0          0  \n",
       "2         0              1        0          0  \n",
       "3         0              0        0          0  \n",
       "4         0              0        0          0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1 - OPEN CLASSIFIER DATASET [currently set to classify pros]\n",
    "# train = pd.read_csv(\"train_old.csv\", header = 0, sep = \",\")\n",
    "train = pd.read_csv(\"train.csv\", header = 0, sep = \",\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004, 15)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>insurance</th>\n",
       "      <th>safety</th>\n",
       "      <th>balance</th>\n",
       "      <th>retirement</th>\n",
       "      <th>culture</th>\n",
       "      <th>racism</th>\n",
       "      <th>sexism</th>\n",
       "      <th>ageism</th>\n",
       "      <th>benefits</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>privacy</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Work life balance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many opportunities off program to explore diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flexible Leadership is strong Challenging Lear...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collaborative culture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Culture Work ethics technology quality experts.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  insurance  safety  \\\n",
       "0                                  Work life balance          0       0   \n",
       "1  Many opportunities off program to explore diff...          0       0   \n",
       "2  Flexible Leadership is strong Challenging Lear...          0       0   \n",
       "3                              Collaborative culture          0       0   \n",
       "4   Culture Work ethics technology quality experts.           0       0   \n",
       "\n",
       "   balance  retirement  culture  racism  sexism  ageism  benefits  \\\n",
       "0        1           0        0       0       0       0         0   \n",
       "1        0           0        0       0       0       0         0   \n",
       "2        1           0        0       0       0       0         0   \n",
       "3        0           0        1       0       0       0         0   \n",
       "4        0           0        1       0       0       0         0   \n",
       "\n",
       "   opportunities  privacy  resources  \n",
       "0              0        0          0  \n",
       "1              1        0          0  \n",
       "2              1        0          0  \n",
       "3              0        0          0  \n",
       "4              0        0          0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop useless data\n",
    "# train = train.drop([\"Unnamed: 0\", \"ID\", \"Initial_ID\", \"S\"], axis = 1)\n",
    "train = train.drop([\"ID\", \"Initial_ID\"], axis = 1)\n",
    "train = train.dropna()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004, 13)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1907\n",
      "1      97\n",
      "Name: insurance, dtype: int64\n",
      "0    1919\n",
      "1      85\n",
      "Name: safety, dtype: int64\n",
      "0    1646\n",
      "1     358\n",
      "Name: balance, dtype: int64\n",
      "0    1965\n",
      "1      39\n",
      "Name: retirement, dtype: int64\n",
      "0    1625\n",
      "1     379\n",
      "Name: culture, dtype: int64\n",
      "0    1984\n",
      "1      20\n",
      "Name: racism, dtype: int64\n",
      "0    1989\n",
      "1      15\n",
      "Name: sexism, dtype: int64\n",
      "0    1992\n",
      "1      12\n",
      "Name: ageism, dtype: int64\n",
      "0    1380\n",
      "1     624\n",
      "Name: benefits, dtype: int64\n",
      "0    1643\n",
      "1     361\n",
      "Name: opportunities, dtype: int64\n",
      "0    2000\n",
      "1       4\n",
      "Name: privacy, dtype: int64\n",
      "0    1909\n",
      "1      95\n",
      "Name: resources, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# review the dataset\n",
    "metrics = ['insurance', 'safety', 'balance', 'retirement', 'culture', 'racism', 'sexism', 'ageism', 'benefits', 'opportunities', 'privacy', 'resources']\n",
    "for metric in metrics:\n",
    "    uvc = train[metric].value_counts(sort = True, ascending = False)\n",
    "    print(uvc)\n",
    "#     uvc.plot(kind = 'bar')\n",
    "#     uvc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big would you like your batch size to be?: 40\n",
      "Batch size will then be 60 and the testing size will be 20.0%.\n",
      "\n",
      "Metric List: ['insurance', 'safety', 'balance', 'retirement', 'culture', 'racism', 'sexism', 'ageism', 'benefits', 'opportunities', 'privacy', 'resources']\n",
      "Which of the 12 metrics would you like to focus on currently?: culture\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = int(input(\"How big would you like your batch size to be?: \"))\n",
    "EVAL_BATCH_SIZE = TRAIN_BATCH_SIZE + 20\n",
    "TEST_PORTION = 0.2\n",
    "print(f'Batch size will then be {EVAL_BATCH_SIZE} and the testing size will be {TEST_PORTION * 100}%.')\n",
    "\n",
    "print(f'\\nMetric List: {metrics}')\n",
    "CURRENT_METRIC = input(f'Which of the {len(metrics)} metrics would you like to focus on currently?: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1603, 2) (401, 2)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 - TOKENIZE INPUT AND CREATE TRAINING/TESTING SETS\n",
    "Xtrain_insurance, Xval_insurance = train_test_split(train[['text', 'insurance']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_safety, Xval_safety = train_test_split(train[['text', 'safety']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_balance, Xval_balance = train_test_split(train[['text', 'balance']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_retirement, Xval_retirement = train_test_split(train[['text', 'retirement']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_culture, Xval_culture = train_test_split(train[['text', 'culture']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_racism, Xval_racism = train_test_split(train[['text', 'racism']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_sexism, Xval_sexism = train_test_split(train[['text', 'sexism']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_ageism, Xval_ageism = train_test_split(train[['text', 'ageism']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_benefits, Xval_benefits = train_test_split(train[['text', 'benefits']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_opportunities, Xval_opportunities = train_test_split(train[['text', 'opportunities']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_privacy, Xval_privacy = train_test_split(train[['text', 'privacy']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_resources, Xval_resources = train_test_split(train[['text', 'resources']], random_state = 0, test_size = TEST_PORTION)\n",
    "\n",
    "print(Xtrain_insurance.shape, Xval_insurance.shape)\n",
    "\n",
    "Xtrains = {\n",
    "    'insurance': Xtrain_insurance,\n",
    "    'safety': Xtrain_safety,\n",
    "    'balance': Xtrain_balance,\n",
    "    'retirement': Xtrain_retirement,\n",
    "    'culture': Xtrain_culture,\n",
    "    'racism': Xtrain_racism,\n",
    "    'sexism': Xtrain_sexism,\n",
    "    'ageism': Xtrain_ageism,\n",
    "    'benefits': Xtrain_benefits,\n",
    "    'opportunities': Xtrain_opportunities,\n",
    "    'privacy': Xtrain_privacy,\n",
    "    'resources': Xtrain_resources\n",
    "}\n",
    "\n",
    "Xvals = {\n",
    "    'insurance': Xval_insurance,\n",
    "    'safety': Xval_safety,\n",
    "    'balance': Xval_balance,\n",
    "    'retirement': Xval_retirement,\n",
    "    'culture': Xval_culture,\n",
    "    'racism': Xval_racism,\n",
    "    'sexism': Xval_sexism,\n",
    "    'ageism': Xval_ageism,\n",
    "    'benefits': Xval_benefits,\n",
    "    'opportunities': Xval_opportunities,\n",
    "    'privacy': Xval_privacy,\n",
    "    'resources': Xval_resources\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For BERT model, the text inputs must be converted to tokens with tokenizer\n",
    "# Here we use a distiled version of BERT base model (DistilBERT) for fast prototyping\n",
    "# https://huggingface.co/distilbert-base-cased \n",
    "# The tokenizer to use is the pretrained DistilBERT tokenizer\n",
    "# https://huggingface.co/transformers/model_doc/distilbert.html#transformers.DistilBertTokenizer\n",
    "# Feel free to try on different pretrained BERT model for your own applications but please remember to match the tokenizer with\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "# With the selected tokenizer, prepare the inputs and labels with correct datatype for each label\n",
    "tokenized_train_insurance = tokenizer(Xtrain_insurance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_insurance = tokenizer(Xval_insurance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_insurance = Xtrain_insurance['insurance'].tolist()\n",
    "val_labels_insurance = Xval_insurance['insurance'].tolist()\n",
    "\n",
    "tokenized_train_safety = tokenizer(Xtrain_safety['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_safety = tokenizer(Xval_safety['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_safety = Xtrain_safety['safety'].tolist()\n",
    "val_labels_safety = Xval_safety['safety'].tolist()\n",
    "\n",
    "tokenized_train_balance = tokenizer(Xtrain_balance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_balance = tokenizer(Xval_balance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_balance = Xtrain_balance['balance'].tolist()\n",
    "val_labels_balance = Xval_balance['balance'].tolist()\n",
    "\n",
    "tokenized_train_retirement = tokenizer(Xtrain_retirement['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_retirement = tokenizer(Xval_retirement['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_retirement = Xtrain_retirement['retirement'].tolist()\n",
    "val_labels_retirement = Xval_retirement['retirement'].tolist()\n",
    "\n",
    "tokenized_train_culture = tokenizer(Xtrain_culture['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_culture = tokenizer(Xval_culture['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_culture = Xtrain_culture['culture'].tolist()\n",
    "val_labels_culture = Xval_culture['culture'].tolist()\n",
    "\n",
    "tokenized_train_racism = tokenizer(Xtrain_racism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_racism = tokenizer(Xval_racism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_racism = Xtrain_racism['racism'].tolist()\n",
    "val_labels_racism = Xval_racism['racism'].tolist()\n",
    "\n",
    "tokenized_train_sexism = tokenizer(Xtrain_sexism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_sexism = tokenizer(Xval_sexism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_sexism = Xtrain_sexism['sexism'].tolist()\n",
    "val_labels_sexism = Xval_sexism['sexism'].tolist()\n",
    "\n",
    "tokenized_train_ageism = tokenizer(Xtrain_ageism['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_ageism = tokenizer(Xval_ageism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_ageism = Xtrain_ageism['ageism'].tolist()\n",
    "val_labels_ageism = Xval_ageism['ageism'].tolist()\n",
    "\n",
    "tokenized_train_benefits = tokenizer(Xtrain_benefits['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_benefits = tokenizer(Xval_benefits['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_benefits = Xtrain_benefits['benefits'].tolist()\n",
    "val_labels_benefits = Xval_benefits['benefits'].tolist()\n",
    "\n",
    "tokenized_train_opportunities = tokenizer(Xtrain_opportunities['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_opportunities = tokenizer(Xval_opportunities['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_opportunities = Xtrain_opportunities['opportunities'].tolist()\n",
    "val_labels_opportunities = Xval_opportunities['opportunities'].tolist()\n",
    "\n",
    "tokenized_train_privacy = tokenizer(Xtrain_privacy['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_privacy = tokenizer(Xval_privacy['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_privacy = Xtrain_privacy['privacy'].tolist()\n",
    "val_labels_privacy = Xval_privacy['privacy'].tolist()\n",
    "\n",
    "tokenized_train_resources = tokenizer(Xtrain_resources['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_resources = tokenizer(Xval_resources['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_resources = Xtrain_resources['resources'].tolist()\n",
    "val_labels_resources = Xval_resources['resources'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataSet with pytorch modules\n",
    "# https://pytorch.org/docs/stable/data.html\n",
    "class MYDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset_insurance = MYDataset(tokenized_train_insurance, train_labels_insurance)\n",
    "val_dataset_insurance = MYDataset(tokenized_val_insurance, val_labels_insurance)\n",
    "train_loader_insurance = DataLoader(train_dataset_insurance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_insurance = DataLoader(val_dataset_insurance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_safety = MYDataset(tokenized_train_safety, train_labels_safety)\n",
    "val_dataset_safety = MYDataset(tokenized_val_safety, val_labels_safety)\n",
    "train_loader_safety = DataLoader(train_dataset_safety, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_safety = DataLoader(val_dataset_safety, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_balance = MYDataset(tokenized_train_balance, train_labels_balance)\n",
    "val_dataset_balance = MYDataset(tokenized_val_balance, val_labels_balance)\n",
    "train_loader_balance = DataLoader(train_dataset_balance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_balance = DataLoader(val_dataset_balance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_retirement = MYDataset(tokenized_train_retirement, train_labels_retirement)\n",
    "val_dataset_retirement = MYDataset(tokenized_val_retirement, val_labels_retirement)\n",
    "train_loader_retirement = DataLoader(train_dataset_retirement, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_retirement = DataLoader(val_dataset_retirement, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_culture = MYDataset(tokenized_train_culture, train_labels_culture)\n",
    "val_dataset_culture = MYDataset(tokenized_val_culture, val_labels_culture)\n",
    "train_loader_culture = DataLoader(train_dataset_culture, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_culture = DataLoader(val_dataset_culture, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_racism = MYDataset(tokenized_train_racism, train_labels_racism)\n",
    "val_dataset_racism = MYDataset(tokenized_val_racism, val_labels_racism)\n",
    "train_loader_racism = DataLoader(train_dataset_racism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_racism = DataLoader(val_dataset_racism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_sexism = MYDataset(tokenized_train_sexism, train_labels_sexism)\n",
    "val_dataset_sexism = MYDataset(tokenized_val_sexism, val_labels_sexism)\n",
    "train_loader_sexism = DataLoader(train_dataset_sexism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_sexism = DataLoader(val_dataset_sexism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_ageism = MYDataset(tokenized_train_ageism, train_labels_ageism)\n",
    "val_dataset_ageism = MYDataset(tokenized_val_ageism, val_labels_ageism)\n",
    "train_loader_ageism = DataLoader(train_dataset_ageism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_ageism = DataLoader(val_dataset_ageism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_benefits = MYDataset(tokenized_train_benefits, train_labels_benefits)\n",
    "val_dataset_benefits = MYDataset(tokenized_val_benefits, val_labels_benefits)\n",
    "train_loader_benefits = DataLoader(train_dataset_benefits, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_benefits = DataLoader(val_dataset_benefits, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_opportunities = MYDataset(tokenized_train_opportunities, train_labels_opportunities)\n",
    "val_dataset_opportunities = MYDataset(tokenized_val_opportunities, val_labels_opportunities)\n",
    "train_loader_opportunities = DataLoader(train_dataset_opportunities, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_opportunities = DataLoader(val_dataset_opportunities, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_privacy = MYDataset(tokenized_train_privacy, train_labels_privacy)\n",
    "val_dataset_privacy = MYDataset(tokenized_val_privacy, val_labels_privacy)\n",
    "train_loader_privacy = DataLoader(train_dataset_privacy, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_privacy = DataLoader(val_dataset_privacy, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_resources = MYDataset(tokenized_train_resources, train_labels_resources)\n",
    "val_dataset_resources = MYDataset(tokenized_val_resources, val_labels_resources)\n",
    "train_loader_resources = DataLoader(train_dataset_resources, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_resources = DataLoader(val_dataset_resources, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "# put all of this into a dictionary to be able to access it all\n",
    "train_datasets = {\n",
    "    'insurance': train_dataset_insurance,\n",
    "    'safety': train_dataset_safety,\n",
    "    'balance': train_dataset_balance,\n",
    "    'retirement': train_dataset_retirement,\n",
    "    'culture': train_dataset_culture,\n",
    "    'racism': train_dataset_racism,\n",
    "    'sexism': train_dataset_sexism,\n",
    "    'ageism': train_dataset_ageism,\n",
    "    'benefits': train_dataset_benefits,\n",
    "    'opportunities': train_dataset_opportunities,\n",
    "    'privacy': train_dataset_privacy,\n",
    "    'resources': train_dataset_resources\n",
    "}\n",
    "\n",
    "train_loaders = {\n",
    "    'insurance': train_loader_insurance,\n",
    "    'safety': train_loader_safety,\n",
    "    'balance': train_loader_balance,\n",
    "    'retirement': train_loader_retirement,\n",
    "    'culture': train_loader_culture,\n",
    "    'racism': train_loader_racism,\n",
    "    'sexism': train_loader_sexism,\n",
    "    'ageism': train_loader_ageism,\n",
    "    'benefits': train_loader_benefits,\n",
    "    'opportunities': train_loader_opportunities,\n",
    "    'privacy': train_loader_privacy,\n",
    "    'resources': train_loader_resources\n",
    "}\n",
    "\n",
    "val_datasets = {\n",
    "    'insurance': val_dataset_insurance,\n",
    "    'safety': val_dataset_safety,\n",
    "    'balance': val_dataset_balance,\n",
    "    'retirement': val_dataset_retirement,\n",
    "    'culture': val_dataset_culture,\n",
    "    'racism': val_dataset_racism,\n",
    "    'sexism': val_dataset_sexism,\n",
    "    'ageism': val_dataset_ageism,\n",
    "    'benefits': val_dataset_benefits,\n",
    "    'opportunities': val_dataset_opportunities,\n",
    "    'privacy': val_dataset_privacy,\n",
    "    'resources': val_dataset_resources\n",
    "}\n",
    "\n",
    "val_loaders = {\n",
    "    'insurance': val_loader_insurance,\n",
    "    'safety': val_loader_safety,\n",
    "    'balance': val_loader_balance,\n",
    "    'retirement': val_loader_retirement,\n",
    "    'culture': val_loader_culture,\n",
    "    'racism': val_loader_racism,\n",
    "    'sexism': val_loader_sexism,\n",
    "    'ageism': val_loader_ageism,\n",
    "    'benefits': val_loader_benefits,\n",
    "    'opportunities': val_loader_opportunities,\n",
    "    'privacy': val_loader_privacy,\n",
    "    'resources': val_loader_resources\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3 - DEFINE PRETRAINED MODEL AND EVALUATE PERFORMANCE\n",
    "# activate GPU runtime by calling cuda\n",
    "device = torch.device(\"cpu\")                         # https://pytorch.org/docs/stable/generated/torch.cuda.device.html?highlight=torch%20device#torch.cuda.device\n",
    "\n",
    "# Find the DistilBert model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\") \n",
    "\n",
    "# Assign model to the GPU device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(loader):\n",
    "    \"\"\" Calculates the true label and predicted label of a dataset's points.\n",
    "    \n",
    "    Args:\n",
    "        loader::[DataLoader]\n",
    "            A dataset's points.\n",
    "            \n",
    "    Return:\n",
    "        y_true::[np.array]\n",
    "            The true labels of the dataset's points.\n",
    "        y_predict::[np.array]\n",
    "            The predicted labels of the dataset's points.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true = []\n",
    "    y_predict = []\n",
    "    count = 1\n",
    "\n",
    "    for batch in loader:\n",
    "        # In batch dictionary, there are a keys for input_ids, attention_mask and labels\n",
    "        # These three inputs are necessary for DistilBertForSequenceClassification model\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "        \n",
    "        # outputs[0] or outputs.loss is the loss and outputs[1] or outputs.logit is the logit\n",
    "        # use torch.argmax to give the one-hot encoding predictions of logits.\n",
    "        # https://huggingface.co/transformers/main_classes/output.html\n",
    "        predictions = torch.argmax(outputs.logits, dim = 1)\n",
    "        \n",
    "        # To call the numpy, you must move the gpu tensors to cpu\n",
    "        y_true_batch = labels.cpu().detach().numpy() \n",
    "        y_predict_batch = predictions.cpu().detach().numpy()\n",
    "        for i in y_true_batch:\n",
    "            y_true.append(i)\n",
    "        for j in y_predict_batch:\n",
    "            y_predict.append(j)\n",
    "            \n",
    "        # Delete the tensors with gradients to save GPU memory\n",
    "        del input_ids\n",
    "        del attention_mask\n",
    "        del labels\n",
    "        del outputs\n",
    "        del predictions\n",
    "\n",
    "        print(f'Batch {count} for current loader completed.')\n",
    "        count += 1\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_predict = np.array(y_predict)\n",
    "\n",
    "    return y_true, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_evaluate(topic, y_true, y_predict):\n",
    "    \"\"\" Makes a classification report and prints a confusion matrix..\n",
    "    \n",
    "    Args:\n",
    "        topic::[string]\n",
    "            The topic of the dataset being analyzed.\n",
    "        y_true::[np.array]\n",
    "            The true labels of the dataset's points.\n",
    "        y_predict::[np.array]\n",
    "            The predicted labels of the dataset's points.\n",
    "    \"\"\"\n",
    "    \n",
    "    target_names = [f'non-{topic}', topic]\n",
    "    \n",
    "    # Use the classification_report module to generate classification report\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "    print(classification_report(y_true, y_predict, target_names = target_names))\n",
    "    \n",
    "    # Use the confusion_matrix module to generate confusion matrix\n",
    "    # Use ConfusionMatrixDisplay to display confusion matrix with lable classes\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay\n",
    "    cm = confusion_matrix(y_true, y_predict)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = target_names)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_val = np.array([])\n",
    "y_predict_val = np.array([])\n",
    "y_true_train = np.array([])\n",
    "y_predict_train = np.array([])\n",
    "\n",
    "def retrieve_trained_model(topic, train_datasets, val_datasets, train_loaders, val_loaders):\n",
    "    \"\"\" Trains a model on a dataset, based on a sub-topic within it.\n",
    "    \n",
    "    Args:\n",
    "        topic::[string]\n",
    "            The sub-topic of the dataset being analyzed.\n",
    "        train_datasets::[MYDataset]\n",
    "            The training dataset's features and labels.\n",
    "        val_datasets::[MYDataset]\n",
    "            The testing dataset's features and labels.\n",
    "        train_loaders::[DataLoader]\n",
    "            The training dataset in the form of an iterable.\n",
    "        val_loaders::[DataLoader]\n",
    "            The testing dataset in the form of an iterable.\n",
    "            \n",
    "    Return:\n",
    "        trainer::[Trainer]\n",
    "            The trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Reminder that there is a total of {train.shape[0]} reviews and the total training batch size is {TRAIN_BATCH_SIZE}.')\n",
    "    print(\"Beginning model training...\")\n",
    "    \n",
    "    # get the true label and predicted label for testing and training set respectively\n",
    "    y_true_val, y_predict_val = predict_dataset(val_loaders[topic])     # [is this needed?]\n",
    "    y_true_train, y_predict_train = predict_dataset(train_loaders[topic])\n",
    "    \n",
    "    print(\"True and predicted values found...\\n\")\n",
    "    \n",
    "    # performance evaluation for training set with pre-trained naive model\n",
    "    print(\"Classification Report on Training Set\")\n",
    "    classification_evaluate(topic, y_true_train, y_predict_train)\n",
    "    \n",
    "    # performance evaluation for testing set with pre-trained naive model\n",
    "    print(\"Classification Report on Testing Set\")\n",
    "    classification_evaluate(topic, y_true_val, y_predict_val)\n",
    "    \n",
    "    # STEP 4 - TRAIN AND EVALUATE THE MODEL\n",
    "    # [MAY HAVE TO CHANGE LATER]\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = './results',                        # output directory\n",
    "        num_train_epochs = 3,                            # total number of training epochs\n",
    "        per_device_train_batch_size = TRAIN_BATCH_SIZE,  # batch size per device during training\n",
    "        per_device_eval_batch_size = EVAL_BATCH_SIZE,    # batch size for evaluation\n",
    "        warmup_steps = 500,                              # number of warmup steps for learning rate scheduler\n",
    "        weight_decay = 0.01,                             # strength of weight decay\n",
    "        logging_dir = './logs',                          # directory for storing logs\n",
    "        logging_steps = 50,                              # record the logs every 10 steps\n",
    "        do_eval = True,                                  # include in the validation set performance evaluation\n",
    "        evaluation_strategy = \"steps\"                    # Loss are calculated along as training step increases\n",
    "    )\n",
    "    \n",
    "    print(\"Training arguments completed...\\n\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = model,                                   # the instantiated  Transformers model to be trained\n",
    "        args = training_args,                            # training arguments, defined above\n",
    "        train_dataset = train_datasets[topic],           # training dataset\n",
    "        eval_dataset = val_datasets[topic]               # evaluation dataset\n",
    "    )\n",
    "\n",
    "    # execute the training\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Classification to Measure Metrics\n",
    "*Currently set to classify only pros*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_title</th>\n",
       "      <th>employee_status</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>IT Analyst</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>R&amp;D Manager</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-16</td>\n",
       "      <td>Chemical Technician</td>\n",
       "      <td>Current Employee, more than 3 years</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Current Employee, more than 10 years</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Company        date       employee_title  \\\n",
       "0           0  ExxonMobil  2021-05-18           IT Analyst   \n",
       "1           1  ExxonMobil  2021-09-04          R&D Manager   \n",
       "2           2  ExxonMobil  2021-10-16  Chemical Technician   \n",
       "3           3  ExxonMobil  2021-10-15            Anonymous   \n",
       "4           4  ExxonMobil  2021-10-13             Engineer   \n",
       "\n",
       "                        employee_status                review_title  \\\n",
       "0    Current Employee, more than 1 year       Great Company Overall   \n",
       "1                       Former Employee       working on energy R&D   \n",
       "2   Current Employee, more than 3 years                 Flexibility   \n",
       "3  Current Employee, more than 10 years      I can only be thankful   \n",
       "4                       Former Employee  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \n",
       "0  I have not experienced anything negative so fa...  \n",
       "1  Difficult industry business environment curren...  \n",
       "2  No downside. PERIOD. Such a great place to joi...  \n",
       "3  It is hard times right now. But for me, it's w...  \n",
       "4  Even if you worked your tail off the whole yea...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open review dataset\n",
    "prelim_reviews = pd.read_csv(\"all_reviews.csv\", header = 0, sep = \";\")\n",
    "prelim_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_title</th>\n",
       "      <th>employee_status</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>IT Analyst</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>R&amp;D Manager</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-16</td>\n",
       "      <td>Chemical Technician</td>\n",
       "      <td>Current Employee, more than 3 years</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Current Employee, more than 10 years</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company        date       employee_title  \\\n",
       "0  ExxonMobil  2021-05-18           IT Analyst   \n",
       "1  ExxonMobil  2021-09-04          R&D Manager   \n",
       "2  ExxonMobil  2021-10-16  Chemical Technician   \n",
       "3  ExxonMobil  2021-10-15            Anonymous   \n",
       "4  ExxonMobil  2021-10-13             Engineer   \n",
       "\n",
       "                        employee_status                review_title  \\\n",
       "0    Current Employee, more than 1 year       Great Company Overall   \n",
       "1                       Former Employee       working on energy R&D   \n",
       "2   Current Employee, more than 3 years                 Flexibility   \n",
       "3  Current Employee, more than 10 years      I can only be thankful   \n",
       "4                       Former Employee  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \n",
       "0  I have not experienced anything negative so fa...  \n",
       "1  Difficult industry business environment curren...  \n",
       "2  No downside. PERIOD. Such a great place to joi...  \n",
       "3  It is hard times right now. But for me, it's w...  \n",
       "4  Even if you worked your tail off the whole yea...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop weird column\n",
    "reviews = prelim_reviews.drop([\"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 500 reviews\n",
      "Done with 1000 reviews\n",
      "Done with 1500 reviews\n",
      "Done with 2000 reviews\n",
      "Done with 2500 reviews\n",
      "Done with 3000 reviews\n",
      "Done with 3500 reviews\n",
      "Done with 4000 reviews\n",
      "Done with 4500 reviews\n",
      "Done with 5000 reviews\n",
      "Done with 5500 reviews\n",
      "Done with 6000 reviews\n",
      "Done with 6500 reviews\n",
      "Done with 7000 reviews\n",
      "Done with 7500 reviews\n",
      "Done with 8000 reviews\n",
      "Done with 8500 reviews\n",
      "Done with 9000 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so far</td>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to join.</td>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company                review_title  \\\n",
       "0  ExxonMobil       Great Company Overall   \n",
       "1  ExxonMobil       working on energy R&D   \n",
       "2  ExxonMobil                 Flexibility   \n",
       "3  ExxonMobil      I can only be thankful   \n",
       "4  ExxonMobil  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \\\n",
       "0    I have not experienced anything negative so far   \n",
       "1  Difficult industry business environment curren...   \n",
       "2   No downside. PERIOD. Such a great place to join.   \n",
       "3  It is hard times right now. But for me, it's w...   \n",
       "4  Even if you worked your tail off the whole yea...   \n",
       "\n",
       "                                                text score_pros score_cons  \\\n",
       "0  pro great work environment great benefit prett...       0.95       0.46   \n",
       "1  pro outstanding colleague working high impact ...       0.32      -0.36   \n",
       "2  pro flexibility nature working like family env...       0.86       0.79   \n",
       "3  pro achieving dream partnership company thankf...       0.77       0.28   \n",
       "4  pro competitive pay structured benefit job sat...        0.7       -0.2   \n",
       "\n",
       "  score_combined  \n",
       "0           0.93  \n",
       "1          -0.05  \n",
       "2           0.92  \n",
       "3           0.78  \n",
       "4           0.66  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean reviews\n",
    "reviews = glass_door_review_cleaner(reviews)\n",
    "reviews[\"text\"] = final_review_cleaner(reviews)\n",
    "# reviews = reviews.dropna()\n",
    "\n",
    "# add sentiment analyses\n",
    "pros_sentiment = retrieve_sentiment_analysis(reviews, \"pros\")\n",
    "cons_sentiment = retrieve_sentiment_analysis(reviews, \"cons\")\n",
    "combined_sentiment = retrieve_sentiment_analysis(reviews, \"text\")\n",
    "\n",
    "reviews[\"score_pros\"] = pros_sentiment[\"compound\"]\n",
    "reviews[\"score_cons\"] = cons_sentiment[\"compound\"]\n",
    "reviews[\"score_combined\"] = combined_sentiment[\"compound\"]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9290, 8)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reminder that there is a total of 2004 reviews and the total training batch size is 40.\n",
      "Beginning model training...\n",
      "Batch 1 for current loader completed.\n",
      "Batch 2 for current loader completed.\n",
      "Batch 3 for current loader completed.\n",
      "Batch 4 for current loader completed.\n",
      "Batch 5 for current loader completed.\n",
      "Batch 6 for current loader completed.\n",
      "Batch 7 for current loader completed.\n",
      "Batch 8 for current loader completed.\n",
      "Batch 9 for current loader completed.\n",
      "Batch 10 for current loader completed.\n",
      "Batch 11 for current loader completed.\n",
      "Batch 12 for current loader completed.\n",
      "Batch 13 for current loader completed.\n",
      "Batch 14 for current loader completed.\n",
      "Batch 15 for current loader completed.\n",
      "Batch 16 for current loader completed.\n",
      "Batch 17 for current loader completed.\n",
      "Batch 18 for current loader completed.\n",
      "Batch 19 for current loader completed.\n",
      "Batch 20 for current loader completed.\n",
      "Batch 21 for current loader completed.\n",
      "Batch 22 for current loader completed.\n",
      "Batch 23 for current loader completed.\n",
      "Batch 24 for current loader completed.\n",
      "Batch 25 for current loader completed.\n",
      "Batch 26 for current loader completed.\n",
      "Batch 27 for current loader completed.\n",
      "Batch 28 for current loader completed.\n",
      "Batch 29 for current loader completed.\n",
      "Batch 30 for current loader completed.\n",
      "Batch 31 for current loader completed.\n",
      "Batch 32 for current loader completed.\n",
      "Batch 33 for current loader completed.\n",
      "Batch 34 for current loader completed.\n",
      "Batch 35 for current loader completed.\n",
      "Batch 36 for current loader completed.\n",
      "Batch 37 for current loader completed.\n",
      "Batch 38 for current loader completed.\n",
      "Batch 39 for current loader completed.\n",
      "Batch 40 for current loader completed.\n",
      "Batch 41 for current loader completed.\n",
      "Batch 1 for current loader completed.\n",
      "Batch 2 for current loader completed.\n",
      "Batch 3 for current loader completed.\n",
      "Batch 4 for current loader completed.\n",
      "Batch 5 for current loader completed.\n",
      "Batch 6 for current loader completed.\n",
      "Batch 7 for current loader completed.\n",
      "Batch 8 for current loader completed.\n",
      "Batch 9 for current loader completed.\n",
      "Batch 10 for current loader completed.\n",
      "Batch 11 for current loader completed.\n",
      "True and predicted values found...\n",
      "\n",
      "Classification Report on Training Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-culture       0.88      0.11      0.19       326\n",
      "     culture       0.19      0.93      0.32        75\n",
      "\n",
      "    accuracy                           0.26       401\n",
      "   macro avg       0.53      0.52      0.26       401\n",
      "weighted avg       0.75      0.26      0.22       401\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 35 291]\n",
      " [  5  70]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 50\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Testing Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-culture       0.78      0.12      0.20      1299\n",
      "     culture       0.19      0.86      0.31       304\n",
      "\n",
      "    accuracy                           0.26      1603\n",
      "   macro avg       0.49      0.49      0.26      1603\n",
      "weighted avg       0.67      0.26      0.22      1603\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 153 1146]\n",
      " [  42  262]]\n",
      "Training arguments completed...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1603\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 40\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 40\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13/123 21:08 < 3:31:28, 0.01 it/s, Epoch 0.29/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insurance_classifier = retrieve_trained_model(CURRENT_METRIC, train_datasets, val_datasets, val_loaders, train_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters in pytorch\n",
    "# You will see the pytorchversion.pkl left hand side files after clicking refresh\n",
    "# Please download this pickle file for future deployment purpose\n",
    "torch.save(model.state_dict(), f'pytorchversion_{CURRENT_METRIC}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Great benefits\n",
      "Label: 0\n",
      "\n",
      "Text: Loved working in teams and collaborations.. \n",
      "Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inspecting misclassified samples in the validation to guide next improvement steps\n",
    "for i in range(2):\n",
    "    text = Xvals[CURRENT_METRIC][y_true_val != y_predict_val].iloc[i]['text']\n",
    "    label = '?'\n",
    "    label = Xvals[CURRENT_METRIC][y_true_val != y_predict_val].iloc[i][CURRENT_METRIC]\n",
    "    print(f'Text: {text}\\nLabel: {label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-insurance       0.93      0.95      0.94        74\n",
      "    insurance       0.20      0.17      0.18         6\n",
      "\n",
      "     accuracy                           0.89        80\n",
      "    macro avg       0.57      0.56      0.56        80\n",
      " weighted avg       0.88      0.89      0.88        80\n",
      "\n",
      "[[70  4]\n",
      " [ 5  1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification_evaluate(y_true_train, y_predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wil\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Wil\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Wil\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-insurance       1.00      0.90      0.95        20\n",
      "    insurance       0.00      0.00      0.00         0\n",
      "\n",
      "     accuracy                           0.90        20\n",
      "    macro avg       0.50      0.45      0.47        20\n",
      " weighted avg       1.00      0.90      0.95        20\n",
      "\n",
      "[[18  2]\n",
      " [ 0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification_evaluate(y_true_val, y_predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric List: ['insurance', 'safety', 'balance', 'retirement', 'culture', 'racism', 'sexism', 'ageism', 'benefits', 'opportunities', 'privacy', 'resources']\n",
      "Which of the 12 metrics would you like to focus on currently?: insurance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5 - FORMAL DEPLOYMENT\n",
    "# Note: If this is an existing session, do NOT run this cell\n",
    "#       If this is a new session, please re-run Step 1 and this cell\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "metrics = ['insurance', 'safety', 'balance', 'retirement', 'culture', 'racism', 'sexism', 'ageism', 'benefits', 'opportunities', 'privacy', 'resources']\n",
    "print(f'Metric List: {metrics}'')\n",
    "CURRENT_METRIC = input(f'Which of the {len(metrics)} metrics would you like to focus on currently?: ')\n",
    "\n",
    "# Load the saved weights to the pretrained the model\n",
    "# model.load_state_dict(torch.load(f'pytorchversion_{CURRENT_METRIC}.pkl', map_location=\"cuda:0\"))\n",
    "model.load_state_dict(torch.load(f'pytorchversion_{CURRENT_METRIC}.pkl', map_location = \"cpu\"))\n",
    "model.to(device)\n",
    "\n",
    "# reload and clean the review dataset\n",
    "prelim_reviews = pd.read_csv(\"all_reviews.csv\", header = 0, sep = \";\")\n",
    "reviews = prelim_reviews.drop([\"Unnamed: 0\"], axis = 1)\n",
    "reviews = glass_door_review_cleaner(reviews)\n",
    "reviews[\"text\"] = final_review_cleaner(reviews)\n",
    "# reviews = reviews.dropna()\n",
    "\n",
    "# add sentiment analyses\n",
    "pros_sentiment = retrieve_sentiment_analysis(reviews, \"pros\")\n",
    "cons_sentiment = retrieve_sentiment_analysis(reviews, \"cons\")\n",
    "combined_sentiment = retrieve_sentiment_analysis(reviews, \"text\")\n",
    "\n",
    "reviews[\"score_pros\"] = pros_sentiment[\"compound\"]\n",
    "reviews[\"score_cons\"] = cons_sentiment[\"compound\"]\n",
    "reviews[\"score_combined\"] = combined_sentiment[\"compound\"]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\Wil/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MYDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "# input_args = [\"i love insurance\", \"resources\", \"i hate their insurance\"]\n",
    "\n",
    "# tokenize Input_arguments \n",
    "tokenized_dep = tokenizer(reviews[\"text\"].astype(str).values.tolist(), padding = \"max_length\", truncation = True)\n",
    "# tokenized_dep = tokenizer(input_args, padding = \"max_length\", truncation = True)\n",
    "\n",
    "# Assumed dep_labels, with the same length of input arguments, if you don't know the exact labels just set them to zeros as example\n",
    "dep_labels = [0] * len(reviews[\"text\"].astype(str).values.tolist())\n",
    "# dep_labels = [0] * len(input_args)\n",
    "\n",
    "# make dep_dataset with Input_arguments and assumed dep_labels\n",
    "dep_dataset = MYDataset(tokenized_dep, dep_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the y_predict of input tokens, similar to the function \"predict_dataset\" shown in STEP3\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dep_loader = DataLoader(dep_dataset, batch_size = 1, shuffle = False)\n",
    "y_predict = []\n",
    "count = 1\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "for batch in dep_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim = 1)\n",
    "    y_predict_batch = predictions.cpu().detach().numpy()\n",
    "    for j in y_predict_batch:\n",
    "        y_predict.append(j)\n",
    "        \n",
    "    del input_ids\n",
    "    del attention_mask\n",
    "    del labels\n",
    "    del outputs\n",
    "    del predictions\n",
    "    \n",
    "    print(f'Batch {count} for current loader completed.')\n",
    "    count += 1\n",
    "\n",
    "y_predict = np.array(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pro pension health insurance benefit rotating ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pro benefit salary people environment campus c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pro overall good place work con reorganization...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pro people assignment opportunity benefit sala...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pro great place work depending career path gro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pro awesome company work con nothing really con</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pro work best brightest challenging fun assign...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pro salary nice campus con toxic culture emplo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pro great environment work culture good collea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pro base salary good plenty time studying self...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pro stability consistency fun past hope verge ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pro excellent training prior smart colleague e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pro great place work good benefit con large co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pro learn lot short period time meet good peop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pro compensation benefit package workplace fle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pro great benefit pay great parental time cons...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pro lot people work delightful willing teach g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pro work quality people lot opportunity job lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pro get work smart people learn great deal ben...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pro huge resource meritocracy intriguin intell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pro career development process based internal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pro benefit best thing company con upper manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pro paid well competitive environment new oppo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pro good work gas always pump con need better ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pro solid pay need much con play lot telephone...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  prediction\n",
       "0   pro great work environment great benefit prett...           0\n",
       "1   pro outstanding colleague working high impact ...           0\n",
       "2   pro flexibility nature working like family env...           0\n",
       "3   pro achieving dream partnership company thankf...           0\n",
       "4   pro competitive pay structured benefit job sat...           0\n",
       "5   pro pension health insurance benefit rotating ...           0\n",
       "6   pro benefit salary people environment campus c...           0\n",
       "7   pro overall good place work con reorganization...           0\n",
       "8   pro people assignment opportunity benefit sala...           0\n",
       "9   pro great place work depending career path gro...           0\n",
       "10    pro awesome company work con nothing really con           0\n",
       "11  pro work best brightest challenging fun assign...           0\n",
       "12  pro salary nice campus con toxic culture emplo...           0\n",
       "13  pro great environment work culture good collea...           0\n",
       "14  pro base salary good plenty time studying self...           0\n",
       "15  pro stability consistency fun past hope verge ...           0\n",
       "16  pro excellent training prior smart colleague e...           0\n",
       "17  pro great place work good benefit con large co...           0\n",
       "18  pro learn lot short period time meet good peop...           0\n",
       "19  pro compensation benefit package workplace fle...           0\n",
       "20  pro great benefit pay great parental time cons...           0\n",
       "21  pro lot people work delightful willing teach g...           0\n",
       "22  pro work quality people lot opportunity job lo...           0\n",
       "23  pro get work smart people learn great deal ben...           0\n",
       "24  pro huge resource meritocracy intriguin intell...           0\n",
       "25  pro career development process based internal ...           0\n",
       "26  pro benefit best thing company con upper manag...           0\n",
       "27  pro paid well competitive environment new oppo...           0\n",
       "28  pro good work gas always pump con need better ...           0\n",
       "29  pro solid pay need much con play lot telephone...           0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the one hot encodings to the 'non-CURRENT_METRIC' and 'CURRENT_METRIC labels'\n",
    "\n",
    "deployment_dict = {\n",
    "    'text': reviews[\"text\"],\n",
    "    'prediction': y_predict\n",
    "}\n",
    "# deployment_dict = {\n",
    "#     'text': input_args,\n",
    "#     'prediction': y_predict\n",
    "# }\n",
    "\n",
    "deployment_output = pd.DataFrame(deployment_dict)\n",
    "deployment_output.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "      <th>insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so far</td>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to join.</td>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company                review_title  \\\n",
       "0  ExxonMobil       Great Company Overall   \n",
       "1  ExxonMobil       working on energy R&D   \n",
       "2  ExxonMobil                 Flexibility   \n",
       "3  ExxonMobil      I can only be thankful   \n",
       "4  ExxonMobil  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \\\n",
       "0    I have not experienced anything negative so far   \n",
       "1  Difficult industry business environment curren...   \n",
       "2   No downside. PERIOD. Such a great place to join.   \n",
       "3  It is hard times right now. But for me, it's w...   \n",
       "4  Even if you worked your tail off the whole yea...   \n",
       "\n",
       "                                                text score_pros score_cons  \\\n",
       "0  pro great work environment great benefit prett...       0.95       0.46   \n",
       "1  pro outstanding colleague working high impact ...       0.32      -0.36   \n",
       "2  pro flexibility nature working like family env...       0.86       0.79   \n",
       "3  pro achieving dream partnership company thankf...       0.77       0.28   \n",
       "4  pro competitive pay structured benefit job sat...        0.7       -0.2   \n",
       "\n",
       "  score_combined  insurance  \n",
       "0           0.93          0  \n",
       "1          -0.05          0  \n",
       "2           0.92          0  \n",
       "3           0.78          0  \n",
       "4           0.66          0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[CURRENT_METRIC] = y_predict\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(f'{CURRENT_METRIC}.csv', sep = ';', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "      <th>insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, review_title, pros, cons, text, score_pros, score_cons, score_combined, insurance]\n",
       "Index: []"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews[CURRENT_METRIC] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
